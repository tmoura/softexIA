{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORNWtG6DG6+Gb/wvk+G9cy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/softexIA/blob/main/17_Exerc%C3%ADcios_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset de Classificação"
      ],
      "metadata": {
        "id": "PnBzARrsK3iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Carregar o dataset através do url abaixo:\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/intro-stat-learning/ISLP/main/ISLP/data/OJ.csv\"\n",
        "\n",
        "# 2) Fazer o One-Hot Encoder na coluna: \"Store7\"\n",
        "# 3) O target é a coluna: \"Purchase\", ela é categórica e deve virar numérica via LabelEncoder\n",
        "# 4) Normalizar todas as features\n",
        "# 5) Dividir os dados em treinamento e teste usando o \"train-test-split\"\n",
        "# 6) Treinar um SVC\n",
        "# 7) Variar os parâmetros do SVC até encontrar uma boa combinação:\n",
        "\n",
        "# Parâmetros default:\n",
        "\n",
        "# C=1.0\n",
        "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
        "# degree=3 (usado com kernel polinomial)\n",
        "\n",
        "# 8) Fazer o predict e mostrar o resultado da taxa de acerto em percentual"
      ],
      "metadata": {
        "id": "euDKHBBkW3hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset de Regressão"
      ],
      "metadata": {
        "id": "hdIDjQYpKPlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/intro-stat-learning/ISLP/main/ISLP/data/Carseats.csv\"\n",
        "\n",
        "# Carregar base de dados\n",
        "# DataFrame\n",
        "df = pd.read_csv(url, header=0)\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "id": "PsP1XLela3E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## One-Hot Encoder \"Store7\"\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "import pandas as pd\n",
        "\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['ShelveLoc','Urban','US']), remainder='passthrough')\n",
        "\n",
        "df = column_transformer.fit_transform(df)\n",
        "\n",
        "df = pd.DataFrame(data=df)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "rE_mjCXcJO7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Separar X e y\n",
        "\n",
        "y = df[7]\n",
        "\n",
        "X = df.drop(7,axis=1)"
      ],
      "metadata": {
        "id": "FSB_pBj1Jj41"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalizar todas as colunas\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "x2 = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x2)\n",
        "X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "91EhnnhQJ7J9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trein-Test-Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None) # 80% treino e 20% teste"
      ],
      "metadata": {
        "id": "f6ky2J9gKArH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## VARIAR OS PARÂMETROS KERNEL, C e Epsilon\n",
        "\n",
        "# C=1.0\n",
        "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
        "# epsilon=0.1\n",
        "# degree=3 (usado com kernel polinomial)\n",
        "\n",
        "# TENTAR ENCONTRAR UMA BOA COMBINAÇÃO DE PARÂMETROS"
      ],
      "metadata": {
        "id": "0TSoO24gW_nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR(kernel='linear',epsilon=0.6)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hfpfXNP7KEnh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "result = model.predict(X_test)\n",
        "print(mean_squared_error(y_test, result))"
      ],
      "metadata": {
        "id": "kkvSuus5KS4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}