{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBykXyEIWfqOEx0mFWT9Ng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/softexIA/blob/main/Avaliando_Hipoteses_Metricas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregamento do Dataset"
      ],
      "metadata": {
        "id": "twN5Pl6GGMvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyeQuZTyW4o9"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "df['target'] = data.target\n",
        "\n",
        "y = df['target']\n",
        "X = df.drop(['target'], axis=1)\n",
        "\n",
        "display(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização de todas as colunas"
      ],
      "metadata": {
        "id": "IcvXH54DawZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "x2 = X.values #retorna um array NumPy\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x2)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "display(X)"
      ],
      "metadata": {
        "id": "ezaSWdCjbJyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Transforma para Array NumPy\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "AIFODme4ZvVn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-*Folds*"
      ],
      "metadata": {
        "id": "ebiCFIYYXsFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "folds = 10\n",
        "\n",
        "kf = StratifiedKFold(n_splits = folds)\n",
        "\n",
        "## 10 conjuntos de dados\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for train_index, test_index in kf.split(X,y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_test.append(X[test_index])\n",
        "\n",
        "  y_train.append(y[train_index])\n",
        "  y_test.append(y[test_index])"
      ],
      "metadata": {
        "id": "MI2FbZ_xXv_5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinar Modelos"
      ],
      "metadata": {
        "id": "dn5jXoTsbss7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(folds):\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  model = model.fit(X_train[i], y_train[i])\n",
        "\n",
        "  result = model.predict(X_test[i])\n",
        "\n",
        "  acc = metrics.accuracy_score(result, y_test[i])\n",
        "\n",
        "  results.append(acc)\n",
        "\n",
        "\n",
        "print(results)\n",
        "show = round(np.mean(results) * 100)\n",
        "print(\"{}%\".format(show))"
      ],
      "metadata": {
        "id": "1nlebFM-bwEA",
        "outputId": "f30c92b8-204f-41f3-bcff-984df384980b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9298245614035088, 0.8421052631578947, 0.9649122807017544, 0.8947368421052632, 0.9824561403508771, 0.9473684210526315, 0.9473684210526315, 0.9122807017543859, 0.9473684210526315, 0.9285714285714286]\n",
            "93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outra opção\n",
        "\n",
        "### usando a função ***cross_val_score***"
      ],
      "metadata": {
        "id": "zgznx4MRcY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "folds = 10\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=folds)\n",
        "\n",
        "print(scores)\n",
        "show = round(np.mean(scores) * 100)\n",
        "print(\"{}%\".format(show))"
      ],
      "metadata": {
        "id": "osMio6r9YIV7",
        "outputId": "056fbdf5-7dfc-4479-e888-3bbf367628d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92982456 0.89473684 0.94736842 0.9122807  0.98245614 0.94736842\n",
            " 0.92982456 0.96491228 0.96491228 0.89285714]\n",
            "94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas de Avaliação"
      ],
      "metadata": {
        "id": "XGa9P7ELaVqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y) # 80% treino e 20% teste\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "result = model.predict(X_test)\n",
        "acc = metrics.accuracy_score(result, y_test)\n",
        "show = round(acc * 100)\n",
        "print(\"{}%\".format(show))"
      ],
      "metadata": {
        "id": "NAL4TpkQanat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Matriz de Confusão:\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(result, y_test))"
      ],
      "metadata": {
        "id": "kBZ_r9nBac7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(result, y_test).ravel()\n",
        "\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp+fn)\n",
        "specificity = tn / (tn+fp)\n",
        "f1_score = (2 * (precision * recall)) / (precision + recall)\n",
        "\n",
        "print(\"Precision: {}%\".format(round(precision * 100)))\n",
        "print(\"Recall: {}%\".format(round(recall * 100)))\n",
        "print(\"Specificity: {}%\".format(round(specificity * 100)))\n",
        "print(\"F1-Score {}%\".format(round(f1_score * 100)))"
      ],
      "metadata": {
        "id": "NNV5jorMb3b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(result, y_test))"
      ],
      "metadata": {
        "id": "59po5n7Nehnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc = metrics.roc_auc_score(result, y_test)\n",
        "\n",
        "print(\"ROC AUC: {}%\".format(round(roc * 100)))"
      ],
      "metadata": {
        "id": "DMQZYGa3oNzN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}