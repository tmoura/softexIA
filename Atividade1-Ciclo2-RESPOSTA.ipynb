{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/softexIA/blob/main/Atividade1-Ciclo2-RESPOSTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 1 - Dataset Digits do sklearn\n",
        "\n",
        "# Acesso: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits\n",
        "\n",
        "# 1) Importar o pacote \"sklearn.datasets\" e o \"load_digits\"\n",
        "# 2) Carregar o dataset através do método: load_digits()\n",
        "# 3) Observe as keys do dataset usando o método \"keys\"\n",
        "# 4) A chave \"data\" são as features e a chave \"target\" é o y. Separe os dados em 2 variáveis diferentes\n",
        "# 5) Separe o conjunto de dados em treinamento e teste usando o método: \"train_test_split\"\n",
        "\n",
        "# 6) Treinar o K-Means, sendo o K seja igual ao número de classes do dataset\n",
        " #(Lembre-se que o predict do K-Means irá retornar o cluster que o dado pertence mas não necessariamente esse número do cluster é a classe correta. Não esqueça de fazer o mapeamento do \"cluster x classe\",\n",
        " # conforme feito no link: https://colab.research.google.com/github/tmoura/machinelearning/blob/master/KMeans.ipynb)\n",
        "# 7) Mostrar a taxa de acerto do K-Means\n",
        "# 8) Calcular a curva do cotovelo para verificar qual o número ideal de clusters para esse dataset\n",
        "# 9) Calcular o Coeficiente de Silhouette para o K-Means treinado em (7)\n",
        "# 10) É possível melhorar o Coeficiente de Silhouette? Altere o K-Means para conseguir um valor melhor do Coeficiente de Silhouette.\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "df = load_digits()\n",
        "\n",
        "y = df.target\n",
        "X = df.data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y) # 80% treino e 20% teste\n",
        "\n",
        "myset = set(y_train) # Cria um conjunto. Em conjuntos, dados não se repetem. Assim, esse conjunto conterá apenas um valor de cada, ou seja: [1,2,3]\n",
        "clusters = len(myset) # Quantos clusters teremos no KMeans\n",
        "\n",
        "model = KMeans(n_clusters = clusters)\n",
        "model = model.fit(X_train)"
      ],
      "metadata": {
        "id": "G5nYixuvuERf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Pegar os labels dos padrões de Treinamento\n",
        "labels = model.labels_\n",
        "\n",
        "map_labels = []\n",
        "\n",
        "for i in range(clusters):\n",
        "  map_labels.append([])\n",
        "\n",
        "new_y_train = y_train.tolist()\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  for c in range(clusters):\n",
        "    if labels[i] == c:\n",
        "      map_labels[c].append(new_y_train[i])\n",
        "\n",
        "#print(map_labels)\n",
        "\n",
        "# Criar dicionário com os labells a serem mapeados\n",
        "mapping = {}\n",
        "\n",
        "for i in range(clusters):\n",
        "  final = Counter(map_labels[i]) # contar a classe que mais aparece\n",
        "  value = final.most_common(1)[0][0] # retorna a classe com maior frequência\n",
        "  mapping[i] = value"
      ],
      "metadata": {
        "id": "rMi7uFXI3lnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sse = {}\n",
        "for k in range(1, 30): # Inicialmente teríamos 10 clusters\n",
        "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X)\n",
        "    sse[k] = kmeans.inertia_ # Inertia: soma das distâncias das instâncias ao centroide mais próximo. Representa o quão coerentes são os clusters internamente.\n",
        "    print(sse[k])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(list(sse.keys()), list(sse.values()))\n",
        "plt.xlabel(\"Número de clusters\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TlA1BPHJ5GYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "result = model.predict(X_test)\n",
        "result = [mapping[i] for i in result]\n",
        "\n",
        "acc = metrics.accuracy_score(result, y_test)\n",
        "show = round(acc * 100)\n",
        "print(\"{}%\".format(show))\n",
        "\n",
        "print(\"Índice Silhouette: %0.3f\" % metrics.silhouette_score(X,y)) #"
      ],
      "metadata": {
        "id": "qVbptuvz4Qow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 2 - Dataset Wine do sklearn\n",
        "\n",
        "# Acesso: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
        "\n",
        "# 1) Importar o pacote \"sklearn.datasets\" e o \"load_wine\"\n",
        "# 2) Carregar o dataset através do método: load_wine()\n",
        "# 3) Observe as keys do dataset usando o método \"keys\"\n",
        "# 4) A chave \"data\" são as features e a chave \"target\" é o y. Separe os dados em 2 variáveis diferentes\n",
        "# 5) Usar todo o conjunto de dados para treinamento\n",
        "# 6) Treinar o DBScan. Quantos clusters foram gerados com os parâmetros que vc escolheu?\n",
        "# 7) Calcular o Coeficiente de Silhouette para o DBScan treinado em (6)\n",
        "# 8) É possível melhorar o Coeficiente de Silhouette? Altere os parâmetros do DBScan para conseguir um valor melhor do coeficiente\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "df = load_wine(as_frame=True)\n",
        "df = df.frame\n",
        "\n",
        "y = df['target']\n",
        "df.drop('target',axis='columns', inplace=True)\n",
        "\n",
        "X = df\n",
        "\n",
        "x2 = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x2)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y) # 80% treino e 20% teste\n",
        "\n",
        "myset = set(y_train) # Cria um conjunto. Em conjuntos, dados não se repetem. Assim, esse conjunto conterá apenas um valor de cada, ou seja: [1,2,3]\n",
        "clusters = len(myset) # Quantos clusters teremos no KMeans\n",
        "\n",
        "# Instância do DBSCAN e aprendizado\n",
        "model = DBSCAN(eps=0.5, min_samples=5).fit(X)\n",
        "core_samples_mask = np.zeros_like(model.labels_, dtype=bool) # Cria matriz de valores False\n",
        "core_samples_mask[model.core_sample_indices_] = True # db.core_sample_indices_ são os índices dos dados que pretencem a algum cluster\n",
        "labels = model.labels_ # Clusters ao qual pertencem os dados\n",
        "\n",
        "display(labels)"
      ],
      "metadata": {
        "id": "7-C8fqfLw5X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de clusters\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print(\"Número estimado de clusters: %d\" % n_clusters_)\n",
        "print(\"Número estimado de outliers ou ruídos: %d\" % n_noise_) # dados que não pertencem a nunhum cluster\n",
        "print(\"Índice Silhouette: %0.3f\" % metrics.silhouette_score(X, y)) # retorna a média do índice de silhouette para todos os exemplos"
      ],
      "metadata": {
        "id": "Fx-BXiw-9-io"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}